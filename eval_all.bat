::Change the path to the best model
::increasing lora r
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.2 --merge_tokens 0  --model_path "path_to_best\clip-vit-large-patch14_None_8_8_0.2_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 16 --lora_dropout 0.2 --merge_tokens 0 --model_path "path_to_best\clip-vit-large-patch14_None_8_16_0.2_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 32 --lora_dropout 0.2 --merge_tokens 0 --model_path "path_to_best\clip-vit-large-patch14_None_8_32_0.2_True_best.pt"
::increasing lora dropout
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.3 --merge_tokens 0 --model_path "path_to_best\clip-vit-large-patch14_None_8_8_0.3_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.4 --merge_tokens 0 --model_path "path_to_best\clip-vit-large-patch14_None_8_8_0.4_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.5 --merge_tokens 0 --model_path "path_to_best\clip-vit-large-patch14_None_8_8_0.5_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.6 --merge_tokens 0 --model_path "path_to_best\clip-vit-large-patch14_None_8_8_0.6_True_best.pt"
::increasing number of tokens
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.2 --merge_tokens 64 --model_path "path_to_best\clip-vit-large-patch14_64_8_8_0.2_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.2 --merge_tokens 96 --model_path "path_to_best\clip-vit-large-patch14_96_8_8_0.2_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.2 --merge_tokens 128 --model_path "path_to_best\clip-vit-large-patch14_128_8_8_0.2_True_best.pt"
python eval.py --name_llm "TinyLlama/TinyLlama-1.1B-Chat-v1.0" --name_img_embed "openai/clip-vit-large-patch14" --batch_size 2 --use_lora True --lora_alpha 8 --lora_r 8 --lora_dropout 0.2 --merge_tokens 192 --model_path "path_to_best\clip-vit-large-patch14_192_8_8_0.2_True_best.pt"
